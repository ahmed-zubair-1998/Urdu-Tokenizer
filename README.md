# Urdu-Tokenizer

This is a text tokenizer for Urdu language. [Google SentencePiece](https://github.com/google/sentencepiece) is used to train a model which is used for tokenization

## Dataset

Dataset courtesy of https://github.com/anuragshas/nlp-for-urdu

Dataset contain 153,814 Urdu Wikipedia articles which were pre-processed

The dataset can be downloaded from here. [Dataset](https://drive.google.com/file/d/15jd1YuQ8kZW3KVDxjhm6kTH7RCyHiPqp/view)
